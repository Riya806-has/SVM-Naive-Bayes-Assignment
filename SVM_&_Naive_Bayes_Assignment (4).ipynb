{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a company that handles email communications.\n",
        "\n",
        "Your task is to automatically classify emails as Spam or Not Spam. The emails may contain:\n",
        "\n",
        "● Text with diverse vocabulary\n",
        "\n",
        "● Potential class imbalance (far more legitimate emails than spam)\n",
        "\n",
        "● Some incomplete or missing data\n",
        "\n",
        "Explain the approach you would take to:\n",
        "\n",
        "● Preprocess the data (e.g. text vectorization, handling missing data)\n",
        "\n",
        "● Choose and justify an appropriate model (SVM vs. Naïve Bayes)\n",
        "\n",
        "● Address class imbalance\n",
        "\n",
        "● Evaluate the performance of your solution with suitable metrics\n",
        "\n",
        "And explain the business impact of your solution.\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "  *  Answer:  explaining the approach to a Spam Detection problem using Python and best practices in machine learning.\n",
        "\n",
        "  1. Preprocessing the Data\n",
        "\n",
        "(a) Text Cleaning & Tokenization:\n",
        "\n",
        "* Lowercasing\n",
        "\n",
        "* Removing stopwords, punctuation\n",
        "\n",
        "* Stemming or lemmatization (optional)\n",
        "\n",
        "(b) Vectorization:\n",
        "\n",
        "* Use TF-IDF Vectorizer to convert text into numerical format:"
      ],
      "metadata": {
        "id": "NUWRrKqITpD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X = vectorizer.fit_transform(email_texts)\n"
      ],
      "metadata": {
        "id": "sVTi1M-RUd1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Handling Missing Data:\n",
        "\n",
        "Remove rows with completely missing emails.\n",
        "\n",
        "If text is missing but label exists: drop or impute as empty string:"
      ],
      "metadata": {
        "id": "in73d743UgfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emails_df['text'] = emails_df['text'].fillna(\"\")\n"
      ],
      "metadata": {
        "id": "nEg1w43GUkvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Model Selection: SVM vs. Naïve Bayes\n",
        "\n",
        "(A) SVM Model:\n",
        "\n",
        "\n",
        "1.   Pros\n",
        "\n",
        "*   Effective in high-dimensional space\n",
        "*   Works well for both linear and non-linear problem\n",
        "\n",
        "*   Robust to overfitting\n",
        "*   Only support vactors are used\n",
        "\n",
        "*   Well defined objective function\n",
        "\n",
        "2.   Cons\n",
        "\n",
        "\n",
        "\n",
        "*   Computationally intensive\n",
        "*   Hard to tune\n",
        "*   Does not scale to big data\n",
        "*   No probobilistic output by default\n",
        "*   Sensitive to outliers\n",
        "\n",
        "(B) Naive Bayes:\n",
        "\n",
        "\n",
        "\n",
        "1.   Pros\n",
        "\n",
        "*   Fast,great with high-dimensional sparse data (like text), handles word independence assumption well.\n",
        "\n",
        "\n",
        "2.   Cons\n",
        "\n",
        "\n",
        "\n",
        "*   Assumes word independence, which is not always realistic.\n",
        "\n",
        "3. Handling Class Imbalance\n",
        "\n",
        "Use class weights (e.g., class_weight='balanced' in SVM)\n",
        "\n",
        "Or use oversampling (like SMOTE) or undersampling\n",
        "\n",
        "Or adjust decision thresholds based on precision-recall tradeoff"
      ],
      "metadata": {
        "id": "8QCZOGJTUn-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=labels)\n"
      ],
      "metadata": {
        "id": "HNjzu_XRUnjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Evaluation Metrics\n",
        "\n",
        "Since spam detection is a class-imbalanced binary classification task, accuracy is not reliable.\n",
        "\n",
        "(A) Use:\n",
        "\n",
        "* Precision: How many predicted spams were actually spam?\n",
        "\n",
        "* Recall: How many actual spams were correctly predicted?\n",
        "\n",
        "* F1-Score: Balance of precision and recall.\n",
        "\n",
        "* ROC-AUC: For probability-based ranking of spam likelihood.\n",
        "\n",
        "5. Business Impact\n",
        "\n",
        "An effective spam filter:\n",
        "\n",
        "* Protects users from phishing or malicious content.\n",
        "\n",
        "* Reduces support costs from spam-related complaints.\n",
        "\n",
        "* Improves user trust and satisfaction, increasing engagement and retention.\n",
        "\n",
        "* Prevents legal issues (e.g., compliance with anti-spam laws)."
      ],
      "metadata": {
        "id": "WJCz9KVUZ3F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python Code Example\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import pandas as pd\n",
        "\n",
        "# Simulated example data\n",
        "data = {\n",
        "    'text': [\n",
        "        'Win money now!!!', 'Important meeting today', '', 'Free lottery tickets',\n",
        "        'Project deadline is tomorrow', 'Click here to claim your prize',\n",
        "        'Let’s catch up over coffee', 'Get rich fast with this simple trick'\n",
        "    ],\n",
        "    'label': [1, 0, 0, 1, 0, 1, 0, 1]  # 1 = Spam, 0 = Not Spam\n",
        "}\n",
        "\n",
        "# Load into DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Fill missing text with empty strings\n",
        "df['text'] = df['text'].fillna(\"\")\n",
        "\n",
        "# Vectorize text using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "y = df['label']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Naïve Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Output evaluation metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXohkNrnaPzZ",
        "outputId": "f1b9b3b1-446c-43de-bdfd-52c0913c46ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.50      0.25         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n",
            "ROC-AUC Score: 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}